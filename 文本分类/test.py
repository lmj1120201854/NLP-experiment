1、使用规则方法判断句子情感极性：
最主要的方法就是将收录有词汇极性是积极或者消极的标注的文档、收录有程度大小的程度副词的文档、收录有停用词的文档到程序中并用词典来保存这些数据。
分类的过程就是将句子分词，产生的词汇在标注词的情感极性的词典里查找，若是积极的则值为1，否则值为-1。将所有的值相加并乘以程度，默认为1。若结果大于零就为这个句子标注积极，否则标注消极。
最有分歧的就是值为零的句子，但是并不能分成中立类。所以此时就有二分之一的概率随机分配，学习效果堪忧。

2、使用概率统计方法实现分类：
最主要的思想就是使用朴素贝叶斯概率统计模型。
以下的X表示语料的分词结果，或者就是语料。Y表示该语料的情感极性标注，Y取值为积极或者消极。
第一步将含有情感极性标签的语料导入到程序中，将其分词，计算P(X|Y=0)和P(X|Y=1)，即在已知Y取值情况下，每个词出现的概率。将其储存在词典中，用于配合先验概率P(Y=0)和P(Y=1)比较后验概率P(Y=1|X)和P(Y=0|X)的大小。
若P(Y=1|X)>P(Y=0|X)，则X为积极语句。
若P(Y=1|X)<P(Y=0|X)，则X为消极语句。
此方法训练效果一般，但是速度较快，属于适中的算法。

3、使用词向量和多层感知机来实现分类：
词向量用于将汉语句子编码、提取特征。多层感知机用于分类。
使用数据集的前一千六百个，八百个积极语句，八百个消极语句，用于MLP的训练。后四百个语句，包括两百个积极语句和两百个消极语句用于测试。
这里做了一个对比试验，第一个使用pytorch搭建的MLP，第二个直接使用sklearn里的MLP分类器。比较两者的效果，sklearn的MLP分类效果更稳定，准确率始终保持在0.975，但是pytorch搭建的MLP神经网络训练波动太大，准确率高低不一，平均百分之九十多。
由于是已经训练好的词向量，所以训练拟合效果较好，准确率很高，但是耗时较一、二方法多。
