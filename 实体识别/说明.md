参考论文《Relation Classification via Convolutional Deep Neural Network》对数据的处理和卷积神经网络的搭建来进行实验的。具体的原理如下图所示：

WF(Word Feature)是基于文本字符的编码，具体就是文本的字符根据转换字典转化而来的序号序列经过词嵌入而获得的词向量。PF(Position Feature)是文本中每个字符的位置编码，是刻画该字符到首尾实体的距离的特征。将WF和PF拼接，形成含有首尾实体位置特征的文本特征，再放入卷积神经网络进行特征提取，再进行分类。
使用的卷积神经网络也是改良的、适合文本分类的卷积神经网络，模型图如上，使用不同大小的卷积核扫描文本，卷积核宽度都是文本特征向量的长度，不同的是卷积核的跨度，即卷积核单次扫描过的字符的数量不同。得到的卷积特征经过最大池化、拼接，形成了经过卷积提取的文本特征，可用该文本特征进行分类。
1、数据预处理：
所给的训练和验证数据集包含首尾实体、文本、标签。最开始要先构建基于字符的转化字典，该字典的作用是方便统计词表长度，并且定义文本转化为对应序号序列的映射规则。

以上是词表搭建的过程，初始化word2token字典是核心数据结构，就是后面字符转化为序号序列的映射规则。Token2word列表的作用是方便解码。
读取数据集，然后根据建表符进行分割字符串，再遍历文本字符，使用add_word方法将字符加入到word2token字典中。最后将获得的字典和解码列表写入到json文件中，方便以后使用。

此处为标签映射和字符映射的读入函数，将保存好的json文件入读，并存放到新的数据结构中，方便后面的调用。


此处为数据预处理最关键的一步，数据集的构建。在这个类里面，会对原数据集进行分割、把文本从字符转化为序列序号token、获取首尾实体的位置并获得padding之后的文本token中每一个词与标定实体的相对位置。

首先是字符转化为token的过程，创建一个列表，遍历文本，将每个字符对应映射规则的序号加入到列表中，形成序号序列token，然后进行padding。

以上是padding的过程，当句子长度小于标定的长度时，填0补充，也就意味着原文中填空格补充。当句子长度大于标定长度时，则截取，删除后续多余的词。不过在本实验中我事先获取了文本最大长度为298，所以我就标定最大文本长度为300，虽然会让所有文本无端填0，并且让训练开销变大，但是也避免了padding之后标定的实体被截取而消失的问题。

接下来获得每个字符相对于实体位置的距离。使用的是以上两个方法，第一个是规范化距离。当当前词在首实体前50个字符位置的时候，我们记距离为0，表示该词在首尾实体划出的文本段的前面50词之前，可视为无关系。当当前词在尾实体后50个字符位置的时候，我们记距离为2 * 50 + 2，表示该词在首尾实体划出的文本段的后面50词之后，也可视为无关系。当当前词在首实体后50个字符以内的时候，我们记距离为50 + 相对距离，所得的这个距离是有效距离。
测试集也是相同的处理，只是没有了标签一列，无需转化标签。

将数据预处理并打包成数据集，并使用dataloader类创建迭代器，按批取出进行训练。
训练数据集结构如下：

验证集完全相同，训练集类似，无标签。

2、卷积神经网络模型搭建：

以上是卷积神经网络的搭建，主要包括三部分：文本内容词嵌入和位置编码词嵌入、卷积、线性层分类。
首先进行词嵌入操作，将数据预处理时获得每个词与首尾实体位置编码pos1和pos2，还有文本的序号序列编码token分别放入到三个不同的Embedding层中进行编码，这三个词嵌入层互不相同、权重也互不相通，分别负责各自位置的词嵌入。
将获得的词嵌入张量先进行升维，将batch_size * max_sentence_len * embed_dimension的张量转化为batch_size * 1 * max_sentence_len * embed_dimension的张量，因为只有除了batch_size以外的三维张量才可以被卷积层进行卷积。
词嵌入层以后会获得一个batch_size * max_sentence_len * embed_dimension、一个batch_size * max_sentence_len * embed_dimension_pos1和一个batch_size * max_sentence_len * embed_dimension_pos2大小的三个张量，然后按最后一个维度进行拼接，变成一个batch_size * max_sentence_len * ( embed_dimension + embed_dimension_pos1 + embed_dimension_pos2)的张量。我们把新的张量的尺寸记为batch_size * max_sentence_len * embed_dimension_total
选择的卷积核跨度有：1，2，3，4。其中跨度为1的卷积核的作用是提取单个词的特征，2，3，4跨度的卷积核是提取相邻词之间的关系特征，有一点文本上下文的含义。
每个跨度的卷积核会有1024个，将会提取出1024个特征，这里不必考虑特征数太多会过拟合，后文有dropout和adam的权衡，都会有效的防止过拟合。
每种卷积核卷积操作结束后，会获得一个batch_size * 1024 * max_sentence_len - span + 1 * embed_dimension_total大小的张量，其中span指的是卷积核跨度，因为步长都是1。之后这个张量会放入到最大池化层，每一个卷积核后会获得一个batch_size * 1024 * 1的张量，一共有四个这种张量，将其拼接，会获得一个batch_size * 1024 * 4的最终文本的特征，该特征具有实体位置编码、上下文语义这些重要信息。
最后将batch_size * 1024 * 4大小的张量放入到全连接层中进行分类即可。
3、训练、验证和预测：

初始化模型对象，并将其送到GPU。
使用交叉熵损失函数来计算损失。
使用Adam优化器，优化网络模型参数，学习率是配置中设置的，后面还有一个防止过拟合的权重。
接下来开始训练。

从数据集迭代器中取出数据放入到模型中，会获得一个y_hat的标签预测概率张量，将其与真实的label放在一起计算loss，然后梯度清零、梯度计算、更新参数。
把y_hat中每一条数据对应的最大概率的标签作为该数据标签，如果与真实标签相同，则预测正确数量加一，反之加零，最后正确数量除以数据集总数就是正确率。还需要统计每一个epoch的loss，以及整个训练过程的平均loss，将其打印，方便观察、统计和调参。

验证过程只有预测和计算正确率、平均loss的工作，并且加了拒绝梯度回传的命令，使得模型并不会拟合验证集，这也保证了验证集的有效性。

测试过程只有预测功能，并将所有的预测结果归纳，并写入到指定文件中。
